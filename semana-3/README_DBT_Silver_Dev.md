# ğŸ§± Databricks Silver Dev Orchestration con DBT + Airflow

[![Databricks](https://img.shields.io/badge/Databricks-FF3621?style=for-the-badge&logo=databricks&logoColor=white)](https://databricks.com/)
[![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=for-the-badge&logo=apache-airflow&logoColor=white)](https://airflow.apache.org/)
[![DBT](https://img.shields.io/badge/dbt-FF694B?style=for-the-badge&logo=dbt&logoColor=white)](https://www.getdbt.com/)
[![Apache Spark](https://img.shields.io/badge/Apache%20Spark-E25A1C?style=for-the-badge&logo=apache-spark&logoColor=white)](https://spark.apache.org/)
[![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org/)

---

## ğŸ“‹ DescripciÃ³n del Proyecto

Este mÃ³dulo amplÃ­a el proyecto de **arquitectura medallÃ³n en Databricks** (Bronzeâ€“Silverâ€“Gold), agregando una **capa paralela de desarrollo (Silver Dev)** orquestada con **Airflow y DBT (Data Build Tool)**.

El objetivo es permitir a los equipos de datos ejecutar y validar sus transformaciones **en un entorno aislado** (`silver_dev`) antes de promover los cambios al entorno **productivo (`silver`)**, siguiendo buenas prÃ¡cticas de versionado, testing y CI/CD para pipelines analÃ­ticos.

---

## ğŸ¯ Objetivos

- Crear un **entorno Silver paralelo** para desarrollo (`silver_dev`)
- Configurar **DBT con Databricks** como motor de ejecuciÃ³n (adapter oficial)
- Orquestar la ejecuciÃ³n de los modelos DBT con **Apache Airflow**
- Mantener aisladas las rutas, catÃ¡logos y esquemas de `silver` y `silver_dev`
- Facilitar **pruebas automatizadas** y **promociÃ³n controlada** a producciÃ³n

---

## ğŸ—ï¸ Arquitectura General

```mermaid
graph TB
  A[Bronze Layer<br/>Raw Data] --> B[DBT Silver Dev<br/>silver_dev schema]
  A --> C[Silver Prod<br/>silver schema]
  B --> D[Airflow DAG<br/>dbt_silver_parallel.py]
  D --> E[DBT Run/Test<br/>dev â†’ prod]
  E --> F[Gold Layer<br/>Analytical Models]
  style B fill:#EAF2FF,stroke:#017CEE
  style C fill:#FFF3E0,stroke:#FF6F00
```

**Resumen:**  
Los notebooks actuales siguen generando y transformando las capas Bronze y Silver (producciÃ³n).  
DBT se encarga de **replicar y probar las transformaciones Silver** en un entorno paralelo, mientras Airflow coordina la ejecuciÃ³n secuencial: `dev` â†’ validaciÃ³n â†’ `prod`.

---

## âš™ï¸ Componentes Clave

| Componente | DescripciÃ³n | PropÃ³sito |
|-------------|--------------|------------|
| **DBT (dbt-databricks)** | Framework de modelado SQL modular | Define y ejecuta transformaciones de datos |
| **Apache Airflow** | Orquestador de pipelines | Coordina tareas `dbt run` y `dbt test` |
| **Databricks Delta Lake** | Formato de almacenamiento ACID | Mantiene las tablas de Silver y Silver Dev |
| **Python / BashOperator** | EjecuciÃ³n de comandos DBT en Airflow | Ejecuta y valida jobs de dbt |

---

## ğŸ§© Estructura del Proyecto

```
databricks-silver-dev-orchestration/
â”œâ”€â”€ DBT_Silver_Dev_Orchestration.ipynb   # GuÃ­a principal paso a paso
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ airflow_dag_dbt_silver.py        # DAG de Airflow para ejecutar dbt (devâ†’prod)
â”œâ”€â”€ dbt_templates/
â”‚   â”œâ”€â”€ profiles.yml.example             # ConfiguraciÃ³n de targets (prod/dev)
â”‚   â”œâ”€â”€ dbt_project.yml.example          # Proyecto base dbt
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ silver_example.sql           # Modelo incremental de ejemplo
â””â”€â”€ README.md                            # Este archivo
```

---

## ğŸ§° Requisitos Previos

- Workspace de **Databricks** con acceso a un Warehouse o Cluster activo  
- **Python 3.8+** y acceso a instalar paquetes (`pip`)  
- **Apache Airflow** operativo (local o en servidor)  
- **Token de Databricks** con permisos de escritura sobre el schema `silver_dev`
- Credenciales configuradas en variables de entorno:
  ```bash
  export DATABRICKS_TOKEN="***"
  export DBT_PROFILES_DIR="/ruta/a/tu/dbt_project"
  export DBT_PROJECT_DIR="/ruta/a/tu/dbt_project"
  ```

---

## ğŸš€ Setup Paso a Paso

### 1ï¸âƒ£ Instalar dependencias

```bash
pip install dbt-databricks apache-airflow
```

### 2ï¸âƒ£ Configurar `profiles.yml`

Define dos entornos (`dev` y `prod`) con sus respectivos esquemas:

```yaml
databricks_project:
  target: dev
  outputs:
    prod:
      type: databricks
      catalog: main
      schema: silver
      host: https://<workspace>.cloud.databricks.com
      http_path: /sql/1.0/warehouses/<WAREHOUSE_ID>
      token: "{{ env_var('DATABRICKS_TOKEN') }}"
    dev:
      type: databricks
      catalog: main
      schema: silver_dev
      host: https://<workspace>.cloud.databricks.com
      http_path: /sql/1.0/warehouses/<WAREHOUSE_ID>
      token: "{{ env_var('DATABRICKS_TOKEN') }}"
```

### 3ï¸âƒ£ Crear proyecto DBT

```bash
dbt init databricks_silver
cp dbt_templates/dbt_project.yml.example dbt_project.yml
```

### 4ï¸âƒ£ Validar conexiÃ³n

```bash
dbt debug --target dev
```

### 5ï¸âƒ£ Ejecutar transformaciones

- En entorno desarrollo:
  ```bash
  dbt run --select tag:silver --target dev
  dbt test --select tag:silver --target dev
  ```
- En producciÃ³n:
  ```bash
  dbt run --select tag:silver --target prod
  dbt test --select tag:silver --target prod
  ```

---

## ğŸŒ€ OrquestaciÃ³n con Airflow

El DAG `airflow_dag_dbt_silver.py` automatiza la secuencia:

1. Limpieza (`dbt clean`)  
2. EjecuciÃ³n en `dev` (`dbt run/test`)  
3. PromociÃ³n a `prod` sÃ³lo si pasa la validaciÃ³n  

```bash
cd dags/
airflow dags list
airflow dags trigger dbt_silver_parallel
```

---

## ğŸ§  Buenas PrÃ¡cticas

- MantÃ©n el **aislamiento entre `silver_dev` y `silver`** (distinto schema/catalog).
- Usa **tags** para segmentar modelos (`tag:silver`, `tag:gold`, etc.).
- Agrega **tests DBT** (`unique`, `not_null`, `relationships`) en cada modelo.
- Versiona tus cambios con **Git + Pull Requests**.
- Automatiza ejecuciÃ³n y despliegues con Airflow o Databricks Jobs.

---

## ğŸ“ˆ Roadmap

| Fase | Objetivo | Estado |
|------|-----------|--------|
| 1 | Configurar entorno DBT + Silver Dev | âœ… |
| 2 | Integrar Airflow para orquestaciÃ³n diaria | âœ… |
| 3 | AÃ±adir CI/CD con GitHub Actions | ğŸ”„ |
| 4 | Incorporar validaciones automÃ¡ticas y alertas | ğŸ”œ |
| 5 | Extender a Gold con DBT | ğŸ”œ |

---

## ğŸ¤ Contribuir

1. **Fork** del repo  
2. **Crea** tu rama (`feature/dbt-upgrade`)  
3. **Commit & push**  
4. **Pull request** con descripciÃ³n clara  

---

## ğŸ“„ Licencia

Este proyecto se distribuye bajo licencia **MIT**.  
Siente total libertad para reutilizar, adaptar y mejorar el cÃ³digo. eso si, pilas con compartir Keys o Secret values

---

## âœ‰ï¸ Contacto

**Autor:** Sebastian Clavijo Correa  
**Rol:** Data Engineer / Miembro comunidad Databricks   
**LinkedIn:** [linkedin.com/in/Sebastian Clavijo Correa](https://linkedin.com/in/tatan](https://www.linkedin.com/in/sebastian-clavijo-correa-446421287))

---

<div align="center">

âœ¨ *Silver Dev es tu sandbox seguro: experimenta, valida y escala sin romper producciÃ³n.* âœ¨  
**â€” Equipo de IngenierÃ­a de Datos â€”**

</div>
